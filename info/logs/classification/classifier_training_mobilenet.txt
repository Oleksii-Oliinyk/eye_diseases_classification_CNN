Epoch #1 -> lr = 0.0002999999999999999
Training: 
              precision    recall  f1-score   support

           0       0.68      0.70      0.69       324
           1       0.67      0.69      0.68       306
           2       0.70      0.54      0.61       205
           3       0.59      0.59      0.59        81
           4       0.68      0.55      0.60       179
           5       0.75      0.87      0.81       271
           6       0.57      0.66      0.61       265
           7       0.65      0.57      0.60       160

    accuracy                           0.67      1791
   macro avg       0.66      0.65      0.65      1791
weighted avg       0.67      0.67      0.66      1791

Evaluation: 
              precision    recall  f1-score   support

           0       0.79      0.43      0.56        35
           1       0.42      0.93      0.57        27
           2       0.67      0.50      0.57        20
           3       0.00      0.00      0.00        10
           4       0.88      0.97      0.92        30
           5       0.96      0.71      0.81        34
           6       0.81      0.62      0.70        21
           7       0.69      0.96      0.80        23

    accuracy                           0.69       200
   macro avg       0.65      0.64      0.62       200
weighted avg       0.72      0.69      0.67       200

Epoch #2 -> lr = 0.00030002293109314187
Training: 
              precision    recall  f1-score   support

           0       0.90      0.93      0.92       324
           1       0.92      0.93      0.93       306
           2       0.90      0.87      0.88       205
           3       0.88      0.85      0.87        81
           4       0.95      0.96      0.95       179
           5       0.97      0.97      0.97       271
           6       0.90      0.87      0.88       265
           7       0.91      0.93      0.92       160

    accuracy                           0.92      1791
   macro avg       0.92      0.91      0.92      1791
weighted avg       0.92      0.92      0.92      1791

Evaluation: 
              precision    recall  f1-score   support

           0       0.88      0.86      0.87        35
           1       0.57      0.93      0.70        27
           2       1.00      0.60      0.75        20
           3       1.00      0.10      0.18        10
           4       1.00      0.87      0.93        30
           5       0.97      0.85      0.91        34
           6       0.67      0.95      0.78        21
           7       0.96      0.96      0.96        23

    accuracy                           0.82       200
   macro avg       0.88      0.76      0.76       200
weighted avg       0.88      0.82      0.82       200

Epoch #3 -> lr = 0.000300091723593552
Training: 
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       324
           1       0.95      0.96      0.96       306
           2       0.94      0.96      0.95       205
           3       0.93      0.88      0.90        81
           4       0.99      0.99      0.99       179
           5       0.99      0.98      0.98       271
           6       0.97      0.98      0.98       265
           7       0.98      0.98      0.98       160

    accuracy                           0.97      1791
   macro avg       0.97      0.96      0.96      1791
weighted avg       0.97      0.97      0.97      1791

Evaluation: 
              precision    recall  f1-score   support

           0       0.83      1.00      0.91        35
           1       0.77      0.89      0.83        27
           2       1.00      0.80      0.89        20
           3       1.00      0.50      0.67        10
           4       1.00      1.00      1.00        30
           5       1.00      0.91      0.95        34
           6       0.95      1.00      0.98        21
           7       0.91      0.91      0.91        23

    accuracy                           0.92       200
   macro avg       0.93      0.88      0.89       200
weighted avg       0.93      0.92      0.91       200

Epoch #4 -> lr = 0.000300206375164213
Training: 
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       324
           1       0.97      0.97      0.97       306
           2       0.97      0.96      0.97       205
           3       0.96      0.96      0.96        81
           4       0.99      0.99      0.99       179
           5       0.99      0.99      0.99       271
           6       0.98      0.99      0.99       265
           7       0.96      0.95      0.96       160

    accuracy                           0.98      1791
   macro avg       0.98      0.98      0.98      1791
weighted avg       0.98      0.98      0.98      1791

Evaluation: 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        35
           1       0.93      0.96      0.95        27
           2       1.00      0.85      0.92        20
           3       1.00      1.00      1.00        10
           4       1.00      1.00      1.00        30
           5       0.92      1.00      0.96        34
           6       0.95      0.95      0.95        21
           7       1.00      0.96      0.98        23

    accuracy                           0.97       200
   macro avg       0.97      0.97      0.97       200
weighted avg       0.97      0.97      0.97       200

Epoch #5 -> lr = 0.00030036688191018273
Validation: 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        35
           1       0.93      0.96      0.95        27
           2       1.00      0.85      0.92        20
           3       1.00      1.00      1.00        10
           4       1.00      1.00      1.00        30
           5       0.92      1.00      0.96        34
           6       0.95      0.95      0.95        21
           7       1.00      0.96      0.98        23

    accuracy                           0.97       200
   macro avg       0.97      0.97      0.97       200
weighted avg       0.97      0.97      0.97       200

