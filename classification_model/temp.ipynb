{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate, train\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs):\n",
    "    scheduler = torch.optim.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=1e-1,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3,\n",
    "        div_factor=25,\n",
    "        final_div_factor=1000,\n",
    "        anneal_strategy='cos'\n",
    "    )\n",
    "\n",
    "    best_eval_f1 = 0\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        train_loss, train_acc, train_prec, train_rec, train_f1 = train(model, criterion, optimizer,device,train_loader)\n",
    "        eval_acc, eval_prec, eval_rec, eval_f1 = evaluate(model,device,test_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Prec: {train_prec:.4f}, Rec: {train_rec:.4f},F1: {train_f1:.4f}\")\n",
    "        wandb.log({\n",
    "                \"Training/Loss\": train_loss,\n",
    "                \"Training/Accuracy\": train_acc,\n",
    "                \"Training/Precision\": train_prec,\n",
    "                \"Training/Recall\": train_rec,\n",
    "                \"Training/F1_Score\": train_f1,\n",
    "                \"Learning_Rate\": optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        print(f\"Eval  - Acc: {eval_acc:.4f}, Prec: {eval_prec:.4f}, Rec: {eval_rec:.4f}, F1: {eval_f1:.4f}\")\n",
    "        wandb.log({\n",
    "        \"Evaluation/Accuracy\": eval_acc,\n",
    "        \"Evaluation/Precision\": eval_prec,\n",
    "        \"Evaluation/Recall\": eval_rec,\n",
    "        \"Evaluation/F1_Score\": eval_f1\n",
    "        })\n",
    "\n",
    "        if eval_f1 > best_eval_f1:\n",
    "            best_eval_f1 = eval_f1\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping на епосі {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        # Крок scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_model(model, criterion, optimizer, EPOCHS_NUM)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
